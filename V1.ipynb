{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoureldinAyman/Drug-Recommendation/blob/nour/V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3qoK9RAwghz"
      },
      "source": [
        "# Personalized Drug Recommendation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd7lFVpkwpTV"
      },
      "source": [
        "## Dataset\n",
        "The dataset is MIMIC-IV\n",
        "\n",
        "\n",
        "It is separated into 4 modules:\n",
        "- [hosp](https://mimic.mit.edu/docs/iv/modules/hosp) - hospital level data for patients: labs, micro, and electronic medication administration\n",
        "- [icu](https://mimic.mit.edu/docs/iv/modules/icu) - ICU level data. These are the event tables, and are identical in structure to MIMIC-III (chartevents, etc)\n",
        "- [ed](https://mimic.mit.edu/docs/iv/modules/ed) - data from the emergency department\n",
        "- [note](https://mimic.mit.edu/docs/iv/modules/note) - deidentified free-text clinical notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI3cZICFttJo"
      },
      "source": [
        "## Data preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LHpkE_Nt8DX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54vS8TARt_Kj",
        "outputId": "319b8795-4434-465d-84cb-e6e63b558bcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDBsGnFVvk6i"
      },
      "source": [
        "Setting the seed for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1gkj2M5uGd5"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "sample_frac = 0.10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMpmuRZzUzYl"
      },
      "source": [
        "Tables used:\n",
        "1. omr table\n",
        "  - The Online Medical Record (OMR) table contains miscellaneous information from the EHR.\n",
        "2. admissions table\n",
        "\t- Detailed information about hospital stays.\n",
        "3. d_labitems\n",
        "\t- Dimension table for labevents provides a description of all lab items.\n",
        "4. diagnoses_icd\n",
        "\t- Billed ICD-9/ICD-10 diagnoses for hospitalizations.\n",
        "5. labevents\n",
        "\t- Laboratory measurements sourced from patient derived specimens.\n",
        "6. microbiologyevents\n",
        "\t- Microbiology cultures.\n",
        "7. patients table\n",
        "\t- Patients' gender, age, and date of death if information exists.\n",
        "8. prescriptions\n",
        "\t- Prescribed medications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F4eW4emVQW5"
      },
      "source": [
        "### Loading datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSYo2bQcU6wx"
      },
      "outputs": [],
      "source": [
        "# Load datasets with relevant columns\n",
        "admissions = pd.read_csv(\"/content/drive/MyDrive/Data/hosp/admissions.csv.gz\",\n",
        "                         compression=\"gzip\",\n",
        "                         usecols=[\"subject_id\", \"hadm_id\", \"admittime\", \"admission_type\",\n",
        "                                  \"admission_location\", \"insurance\", \"language\", \"marital_status\", \"race\"],\n",
        "                         nrows=1000)\n",
        "\n",
        "patients = pd.read_csv(\"/content/drive/MyDrive/Data/hosp/patients.csv.gz\",\n",
        "                       compression=\"gzip\",\n",
        "                       usecols=[\"subject_id\", \"gender\", \"anchor_age\"],\n",
        "                       nrows=1000)\n",
        "\n",
        "omr = pd.read_csv(\"/content/drive/MyDrive/Data/hosp/omr.csv.gz\",\n",
        "                  compression=\"gzip\",\n",
        "                  usecols=[\"subject_id\", \"chartdate\", \"seq_num\", \"result_name\", \"result_value\"],\n",
        "                  nrows=1000)\n",
        "\n",
        "labevents = pd.read_csv(\"/content/drive/MyDrive/Data/hosp/labevents.csv.gz\",\n",
        "                        compression=\"gzip\",\n",
        "                        usecols=[\"subject_id\", \"hadm_id\", \"itemid\", \"charttime\", \"valuenum\", \"valueuom\", \"flag\"],\n",
        "                        nrows=1000)\n",
        "\n",
        "# d_labitems = pd.read_csv(\"/content/drive/MyDrive/Data/hosp/d_labitems.csv.gz\",\n",
        "#                          compression=\"gzip\",\n",
        "#                          usecols=[\"itemid\", \"label\"])\n",
        "\n",
        "microbiologyevents = pd.read_csv(\"/content/drive/MyDrive/Data/hosp/microbiologyevents.csv.gz\",\n",
        "                                 compression=\"gzip\",\n",
        "                                 usecols=[\"subject_id\", \"hadm_id\", \"charttime\", \"spec_type_desc\", \"org_name\"],\n",
        "                                 nrows=1000)\n",
        "\n",
        "diagnoses_icd = pd.read_csv(\"/content/drive/MyDrive/Data/hosp/diagnoses_icd.csv.gz\",\n",
        "                            compression=\"gzip\",\n",
        "                            usecols=[\"subject_id\", \"hadm_id\", \"icd_code\", \"icd_version\"],\n",
        "                            nrows=1000)\n",
        "\n",
        "prescriptions = pd.read_csv(\"/content/drive/MyDrive/Data/hosp/prescriptions.csv.gz\",\n",
        "                            compression=\"gzip\",\n",
        "                            usecols=[\"subject_id\", \"hadm_id\", \"drug\", \"dose_val_rx\", \"dose_unit_rx\",\n",
        "                                     \"starttime\", \"stoptime\"],\n",
        "                            nrows=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SeFuoNuZQJO",
        "outputId": "8f95f678-d88a-4ca0-d612-1ce9689dfff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "admissions shape: (1000, 9)\n",
            "patients shape: (1000, 3)\n",
            "omr shape: (1000, 5)\n",
            "labevents shape: (1000, 7)\n",
            "microbiologyevents shape: (1000, 5)\n",
            "diagnoses_icd shape: (1000, 4)\n",
            "prescriptions shape: (1000, 7)\n"
          ]
        }
      ],
      "source": [
        "print(f\"admissions shape: {admissions.shape}\")\n",
        "print(f\"patients shape: {patients.shape}\")\n",
        "print(f\"omr shape: {omr.shape}\")\n",
        "print(f\"labevents shape: {labevents.shape}\")\n",
        "# print(f\"d_labitems shape: {d_labitems.shape}\")\n",
        "print(f\"microbiologyevents shape: {microbiologyevents.shape}\")\n",
        "print(f\"diagnoses_icd shape: {diagnoses_icd.shape}\")\n",
        "print(f\"prescriptions shape: {prescriptions.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S2XbDkUlpCO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWHdoFFZYAn-"
      },
      "source": [
        "### Merging the datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnaIMIpqZ42m"
      },
      "source": [
        "Starting from the base admissions table, I'm going to:\n",
        "- Create a copy of the base admissions.\n",
        "- Merge admissions copy with patients on `subject_id` with left join.\n",
        "- Merge with diagnoses on `subject_id`.\n",
        "- Merge with prescriptions on `subject_id` and `hadm_id`.\n",
        "- Merge with labevents on `subject_id` and `hadm_id`.\n",
        "- Merge with microbiologyevents on `subject_id` and `hadm_id`.\n",
        "\n",
        "All merges are done with left join to preserve the records in the admissions table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxXmFuxUXzjg"
      },
      "outputs": [],
      "source": [
        "# Start with admissions as the base table\n",
        "dataset = admissions.copy()\n",
        "\n",
        "# Merge with patients using subject_id\n",
        "dataset = dataset.merge(patients, on='subject_id', how='left')\n",
        "\n",
        "# Merge with diagnoses_icd using subject_id and hadm_id\n",
        "dataset = dataset.merge(diagnoses_icd, on=['subject_id', 'hadm_id'], how='left')\n",
        "\n",
        "# Merge with prescriptions using subject_id and hadm_id\n",
        "dataset = dataset.merge(prescriptions, on=['subject_id', 'hadm_id'], how='left')\n",
        "\n",
        "# Merge with labevents using subject_id and hadm_id\n",
        "dataset = dataset.merge(labevents, on=['subject_id', 'hadm_id'], how='left')\n",
        "\n",
        "# Merge with microbiologyevents using subject_id and hadm_id\n",
        "dataset = dataset.merge(microbiologyevents, on=['subject_id', 'hadm_id'], how='left')\n",
        "\n",
        "# Merge with omr using subject_id\n",
        "dataset = dataset.merge(omr, on='subject_id', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrRpK4MIFfu2"
      },
      "source": [
        "Validate the result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9P_B0U3FecF",
        "outputId": "72f46b68-d20f-476e-9b4f-7f2efc925f3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of merged data: (7052413, 30)\n",
            "Missing values in key columns:\n",
            "subject_id    0\n",
            "hadm_id       0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of merged data:\", dataset.shape)\n",
        "print(\"Missing values in key columns:\")\n",
        "print(dataset[['subject_id', 'hadm_id']].isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4DBcjGQU33Q",
        "outputId": "a076f4a3-8794-46ce-fc9b-89030bffb67a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['subject_id', 'hadm_id', 'admittime', 'admission_type',\n",
              "       'admission_location', 'insurance', 'language', 'marital_status', 'race',\n",
              "       'gender', 'anchor_age', 'icd_code', 'icd_version', 'starttime',\n",
              "       'stoptime', 'drug', 'dose_val_rx', 'dose_unit_rx', 'itemid',\n",
              "       'charttime_x', 'valuenum', 'valueuom', 'flag', 'charttime_y',\n",
              "       'spec_type_desc', 'org_name', 'chartdate', 'seq_num', 'result_name',\n",
              "       'result_value'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr2gq-lqU6V0",
        "outputId": "aeba3ef6-3be0-4d63-fe82-3f47ce733b8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7052413, 30)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI-0WAzhUMqd"
      },
      "source": [
        "### Encoding/Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1bGnnaUHgMp",
        "outputId": "fd661e5c-d7ad-4882-803b-934aa01ec55e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numerical columns:\n",
            "Index(['subject_id', 'hadm_id', 'anchor_age', 'icd_version', 'itemid',\n",
            "       'valuenum', 'seq_num'],\n",
            "      dtype='object')\n",
            "Categorical columns:\n",
            "Index(['admittime', 'admission_type', 'admission_location', 'insurance',\n",
            "       'language', 'marital_status', 'race', 'gender', 'icd_code', 'starttime',\n",
            "       'stoptime', 'drug', 'dose_val_rx', 'dose_unit_rx', 'charttime_x',\n",
            "       'valueuom', 'flag', 'charttime_y', 'spec_type_desc', 'org_name',\n",
            "       'chartdate', 'result_name', 'result_value'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "numerical_cols = dataset.select_dtypes(include=[\"number\"]).columns\n",
        "print(\"Numerical columns:\")\n",
        "print(numerical_cols)\n",
        "\n",
        "categorical_cols = dataset.select_dtypes(include=[\"object\", \"category\"]).columns\n",
        "print(\"Categorical columns:\")\n",
        "print(categorical_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBrQpICdbK0s",
        "outputId": "872987da-fedb-422e-d1ca-2d7165ab9932"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "admittime has 1000 unique values\n",
            "Examples: ['2180-05-06 22:23:00' '2180-06-26 18:27:00' '2180-08-05 23:44:00'\n",
            " '2180-07-23 12:35:00' '2160-03-03 23:16:00' '2160-11-21 01:56:00'\n",
            " '2160-12-28 05:11:00' '2163-09-27 23:17:00' '2181-11-15 02:05:00'\n",
            " '2183-09-18 18:10:00' '2163-08-20 01:42:00' '2192-11-30 01:25:00'\n",
            " '2151-03-18 03:28:00' '2189-10-15 10:30:00' '2143-12-23 14:55:00']\n",
            "-------------------------------------------\n",
            "admission_type has 9 unique values\n",
            "Examples: ['URGENT' 'EW EMER.' 'EU OBSERVATION' 'OBSERVATION ADMIT'\n",
            " 'SURGICAL SAME DAY ADMISSION' 'AMBULATORY OBSERVATION' 'DIRECT EMER.'\n",
            " 'DIRECT OBSERVATION' 'ELECTIVE']\n",
            "-------------------------------------------\n",
            "admission_location has 11 unique values\n",
            "Examples: ['TRANSFER FROM HOSPITAL' 'EMERGENCY ROOM' 'WALK-IN/SELF REFERRAL'\n",
            " 'PHYSICIAN REFERRAL' 'PROCEDURE SITE' 'CLINIC REFERRAL'\n",
            " 'TRANSFER FROM SKILLED NURSING FACILITY' 'PACU'\n",
            " 'INTERNAL TRANSFER TO OR FROM PSYCH' 'INFORMATION NOT AVAILABLE'\n",
            " 'AMBULATORY SURGERY TRANSFER']\n",
            "-------------------------------------------\n",
            "insurance has 5 unique values\n",
            "Examples: ['Medicaid' nan 'Medicare' 'Private' 'Other']\n",
            "-------------------------------------------\n",
            "language has 13 unique values\n",
            "Examples: ['English' 'Other' 'Russian' 'Kabuverdianu' 'Spanish'\n",
            " 'American Sign Language' 'Vietnamese' 'Portuguese' nan\n",
            " 'Modern Greek (1453-)' 'Haitian' 'Persian' 'French']\n",
            "-------------------------------------------\n",
            "marital_status has 5 unique values\n",
            "Examples: ['WIDOWED' 'SINGLE' 'MARRIED' 'DIVORCED' nan]\n",
            "-------------------------------------------\n",
            "race has 25 unique values\n",
            "Examples: ['WHITE' 'OTHER' 'BLACK/AFRICAN AMERICAN' 'UNABLE TO OBTAIN' 'UNKNOWN'\n",
            " 'WHITE - RUSSIAN' 'BLACK/CAPE VERDEAN'\n",
            " 'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER' 'PORTUGUESE'\n",
            " 'WHITE - OTHER EUROPEAN' 'HISPANIC/LATINO - PUERTO RICAN' 'ASIAN'\n",
            " 'ASIAN - CHINESE' 'HISPANIC/LATINO - DOMINICAN'\n",
            " 'HISPANIC/LATINO - SALVADORAN']\n",
            "-------------------------------------------\n",
            "gender has 2 unique values\n",
            "Examples: ['F' 'M']\n",
            "-------------------------------------------\n",
            "icd_code has 485 unique values\n",
            "Examples: ['5723' '78959' '5715' '07070' '496' '29680' '30981' 'V1582' '07071'\n",
            " '2875' '2761' 'V08' '3051' '07054' 'V462']\n",
            "-------------------------------------------\n",
            "starttime has 397 unique values\n",
            "Examples: ['2180-05-08 08:00:00' '2180-05-07 02:00:00' '2180-05-07 01:00:00'\n",
            " '2180-05-07 00:00:00' '2180-06-27 08:00:00' '2180-06-26 23:00:00'\n",
            " '2180-06-26 22:00:00' '2180-06-27 18:00:00' '2180-08-06 03:00:00'\n",
            " '2180-08-06 17:00:00' '2180-08-07 08:00:00' '2180-08-06 09:00:00'\n",
            " '2180-08-06 21:00:00' '2180-08-06 20:00:00' '2180-08-06 12:00:00']\n",
            "-------------------------------------------\n",
            "stoptime has 279 unique values\n",
            "Examples: ['2180-05-07 22:00:00' '2180-05-07 09:00:00' '2180-05-07 01:00:00'\n",
            " '2180-06-27 23:00:00' '2180-06-26 22:00:00' '2180-08-07 22:00:00'\n",
            " '2180-08-06 19:00:00' '2180-08-06 11:00:00' '2180-08-06 02:00:00'\n",
            " '2180-07-24 10:00:00' '2180-07-25 22:00:00' '2180-07-24 20:00:00'\n",
            " '2180-07-23 23:00:00' '2180-07-25 09:00:00' nan]\n",
            "-------------------------------------------\n",
            "drug has 187 unique values\n",
            "Examples: ['Furosemide' 'Ipratropium Bromide Neb' 'Potassium Chloride'\n",
            " 'Sodium Chloride 0.9%  Flush' 'Raltegravir' 'Spironolactone'\n",
            " 'Acetaminophen' 'Influenza Vaccine Quadrivalent' 'Albuterol Inhaler'\n",
            " 'Emtricitabine-Tenofovir (Truvada)' 'Heparin' 'Nicotine Patch'\n",
            " 'Rifaximin' 'Calcium Carbonate' 'Albumin 25% (12.5g / 50mL)']\n",
            "-------------------------------------------\n",
            "dose_val_rx has 74 unique values\n",
            "Examples: ['40' '1' '20' '3' '400' '50' '500' '0.5' '2' '5000' '14' '550' '1250'\n",
            " '37.5' '30']\n",
            "-------------------------------------------\n",
            "dose_unit_rx has 21 unique values\n",
            "Examples: ['mg' 'NEB' 'mEq' 'mL' 'PUFF' 'TAB' 'UNIT' 'g' 'CAP' 'BAG' 'gm' nan 'LOZ'\n",
            " 'PTCH' 'Appl']\n",
            "-------------------------------------------\n",
            "charttime_x has 19 unique values\n",
            "Examples: ['2180-05-07 00:10:00' '2180-05-07 05:05:00' '2180-05-07 10:11:00'\n",
            " '2180-06-26 22:45:00' '2180-06-27 05:10:00' '2180-08-06 06:36:00'\n",
            " '2180-08-06 15:40:00' '2180-08-07 00:59:00' '2180-08-07 06:15:00'\n",
            " '2180-07-23 21:45:00' '2180-07-24 06:35:00' '2180-07-25 04:45:00' nan\n",
            " '2160-11-20 22:30:00' '2160-11-21 07:00:00']\n",
            "-------------------------------------------\n",
            "valueuom has 19 unique values\n",
            "Examples: ['mg/dL' nan 'units' ' ' '%' 'g/dL' 'pg' 'fL' 'K/uL' 'm/uL' 'sec' 'IU/L'\n",
            " 'mEq/L' '#/uL' '#/hpf']\n",
            "-------------------------------------------\n",
            "flag has 2 unique values\n",
            "Examples: [nan 'abnormal']\n",
            "-------------------------------------------\n",
            "charttime_y has 111 unique values\n",
            "Examples: ['2180-05-07 00:10:00' '2180-05-07 00:19:00' '2180-05-07 10:11:00'\n",
            " '2180-06-26 22:39:00' '2180-06-26 22:45:00' '2180-08-06 20:35:00'\n",
            " '2180-07-23 14:14:00' '2180-07-24 00:55:00' nan '2160-11-21 07:00:00'\n",
            " '2160-11-21 09:30:00' '2189-10-15 13:00:00' '2150-09-20 13:45:00'\n",
            " '2150-09-20 14:45:00' '2150-09-21 08:56:00']\n",
            "-------------------------------------------\n",
            "spec_type_desc has 18 unique values\n",
            "Examples: ['URINE' 'SWAB' 'PERITONEAL FLUID' 'MRSA SCREEN' nan 'BLOOD CULTURE'\n",
            " 'STOOL' 'FLUID RECEIVED IN BLOOD CULTURE BOTTLES' 'Immunology (CMV)'\n",
            " 'Blood (EBV)' 'SEROLOGY/BLOOD' 'SPUTUM' 'TISSUE' 'FOREIGN BODY'\n",
            " 'CSF;SPINAL FLUID']\n",
            "-------------------------------------------\n",
            "org_name has 13 unique values\n",
            "Examples: [nan 'ESCHERICHIA COLI' 'GRAM POSITIVE BACTERIA' 'CANDIDA PARAPSILOSIS'\n",
            " 'YEAST, PRESUMPTIVELY NOT C. ALBICANS' 'STAPH AUREUS COAG +'\n",
            " 'FUSOBACTERIUM NUCLEATUM' 'STREPTOCOCCUS ANGINOSUS (MILLERI) GROUP'\n",
            " 'STAPHYLOCOCCUS, COAGULASE NEGATIVE' 'ENTEROCOCCUS FAECALIS'\n",
            " 'BACTEROIDES FRAGILIS GROUP' 'CITROBACTER FREUNDII COMPLEX' 'YEAST']\n",
            "-------------------------------------------\n",
            "chartdate has 372 unique values\n",
            "Examples: ['2180-04-27' '2180-05-07' '2180-05-25' '2180-06-01' '2180-06-22'\n",
            " '2180-06-27' '2180-06-30' '2180-07-09' '2180-08-06' nan '2160-11-21'\n",
            " '2174-10-14' '2175-01-26' '2175-01-27' '2175-03-17']\n",
            "-------------------------------------------\n",
            "result_name has 5 unique values\n",
            "Examples: ['Blood Pressure' 'Weight (Lbs)' 'BMI (kg/m2)' 'Height (Inches)' nan]\n",
            "-------------------------------------------\n",
            "result_value has 565 unique values\n",
            "Examples: ['110/65' '94' '18.0' '60' '92.15' '106/60' '18.6' '95' '121/77' '18.7'\n",
            " '95.7' '100/60' '18.9' '97' '19.2']\n",
            "-------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for cat_col in categorical_cols:\n",
        "    uniques = dataset[cat_col].unique()\n",
        "    print(f\"{cat_col} has {len(uniques)} unique values\")\n",
        "    print(f\"Examples: {uniques[:15]}\")\n",
        "    print(\"-------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlxzXFHWeGog"
      },
      "source": [
        "Chart times are represented in year-month-day using strings. I will convert them them to YYYYMM in integers. Where Y is year and M is month."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHxrd1aSa1QT",
        "outputId": "e84a60a9-f6c8-45eb-a1d6-79fd3bcb550d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time columns: ['admittime', 'starttime', 'stoptime', 'charttime_x', 'charttime_y', 'chartdate']\n",
            "Original sample of time columns:\n",
            "admittime: ['2180-05-06 22:23:00', '2180-05-06 22:23:00', '2180-05-06 22:23:00', '2180-05-06 22:23:00', '2180-05-06 22:23:00']\n",
            "starttime: ['2180-05-08 08:00:00', '2180-05-08 08:00:00', '2180-05-08 08:00:00', '2180-05-08 08:00:00', '2180-05-08 08:00:00']\n",
            "stoptime: ['2180-05-07 22:00:00', '2180-05-07 22:00:00', '2180-05-07 22:00:00', '2180-05-07 22:00:00', '2180-05-07 22:00:00']\n",
            "charttime_x: ['2180-05-07 00:10:00', '2180-05-07 00:10:00', '2180-05-07 00:10:00', '2180-05-07 00:10:00', '2180-05-07 00:10:00']\n",
            "charttime_y: ['2180-05-07 00:10:00', '2180-05-07 00:10:00', '2180-05-07 00:10:00', '2180-05-07 00:10:00', '2180-05-07 00:10:00']\n",
            "chartdate: ['2180-04-27', '2180-04-27', '2180-05-07', '2180-05-07', '2180-05-07']\n"
          ]
        }
      ],
      "source": [
        "# Identify time-related columns\n",
        "time_cols = [col for col in dataset.columns if 'time' in col.lower() or 'date' in col.lower()]\n",
        "print(\"Time columns:\", time_cols)\n",
        "\n",
        "# Check original data\n",
        "print(\"Original sample of time columns:\")\n",
        "for col in time_cols:\n",
        "    print(f\"{col}: {dataset[col].head().tolist()}\")\n",
        "\n",
        "# Convert to datetime and then to YYYYMM\n",
        "for col in time_cols:\n",
        "    # Convert to string to avoid type issues\n",
        "    dataset[col] = dataset[col].astype(str)\n",
        "    # Convert to datetime, coerce invalid values to NaT\n",
        "    dataset[col] = pd.to_datetime(dataset[col], errors=\"coerce\")\n",
        "    # Convert to YYYYMM, fill NaT with 0, cast to int\n",
        "    dataset[col] = (dataset[col].dt.year * 100 + dataset[col].dt.month).fillna(0).astype(int)\n",
        "\n",
        "# Check results\n",
        "print(\"Sample of converted columns:\")\n",
        "print(dataset[time_cols].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMwnvNO6nTzQ"
      },
      "source": [
        "One hot encoding categorical columns except for admission type as it is ordinal.\n",
        "\n",
        "\"admission_type is useful for classifying the urgency of the admission. There are 9 possibilities: ‘AMBULATORY OBSERVATION’, ‘DIRECT EMER.’, ‘DIRECT OBSERVATION’, ‘ELECTIVE’, ‘EU OBSERVATION’, ‘EW EMER.’, ‘OBSERVATION ADMIT’, ‘SURGICAL SAME DAY ADMISSION’, ‘URGENT’.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDv6B8QEtOmb"
      },
      "outputs": [],
      "source": [
        "filtered_rows = dataset[\"admission_type\"]\n",
        "\n",
        "filtered_rows.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kt1IPZs4f_DE"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# One hot encode all categorical columns except for admission type as it is ordinal.\n",
        "one_hot_cols = [col for col in categorical_cols if col != 'admission_type']\n",
        "\n",
        "admission_order = ['AMBULATORY OBSERVATION', 'DIRECT EMER.', 'DIRECT OBSERVATION','ELECTIVE',\n",
        "                   'EU OBSERVATION', 'EW EMER.', 'OBSERVATION ADMIT', 'SURGICAL SAME DAY ADMISSION', 'URGENT']\n",
        "ordinal_encoder = OrdinalEncoder(categories=[admission_order])\n",
        "dataset['admission_type_encoded'] = ordinal_encoder.fit_transform(dataset[['admission_type']]).ravel()\n",
        "\n",
        "dataset = dataset.drop('admission_type', axis=1)\n",
        "\n",
        "dataset_encoded = pd.get_dummies(dataset, columns=one_hot_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fh7DaF1KoYCb",
        "outputId": "2661e618-5d49-423e-883b-127fefb8bd6a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>admission_type_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ],
            "text/plain": [
              "0    8.0\n",
              "1    8.0\n",
              "2    8.0\n",
              "3    8.0\n",
              "4    8.0\n",
              "Name: admission_type_encoded, dtype: float64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_rows = dataset[\"admission_type_encoded\"]\n",
        "\n",
        "filtered_rows.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1K_LC0Bt_Z0"
      },
      "source": [
        "See the max and min of numerical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNoQGq_xomkS"
      },
      "outputs": [],
      "source": [
        "# Print min and max for each numerical column\n",
        "for col in numerical_cols.columns:\n",
        "    print(f\"{col}: min = {numerical_cols[col].min()}, max = {numerical_cols[col].max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8pnKo7BuESy"
      },
      "outputs": [],
      "source": [
        "dataset_encoded.drop([\"subject_id\", \"hadm_id\"], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSiQO1RzwL8a"
      },
      "outputs": [],
      "source": [
        "dataset_encoded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJigpaMiwZC1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1) Prepare your dataframe (dataset_encoded from before)\n",
        "df = dataset_encoded.copy()\n",
        "\n",
        "# 2) Split features / targets\n",
        "TARGET_CLF = ['icd_code','drug','dose_unit_rx']\n",
        "TARGET_REG = ['dose_val_rx','starttime','stoptime']\n",
        "X = df.drop(columns=TARGET_CLF + TARGET_REG)\n",
        "y_clf = df[TARGET_CLF].astype(str)   # ensure strings\n",
        "y_reg = df[TARGET_REG].astype(float) # floats\n",
        "\n",
        "# 3) Encode categorical targets\n",
        "le_icd   = LabelEncoder().fit(y_clf['icd_code'])\n",
        "le_drug  = LabelEncoder().fit(y_clf['drug'])\n",
        "le_unit  = LabelEncoder().fit(y_clf['dose_unit_rx'])\n",
        "\n",
        "y_clf_enc = pd.DataFrame({\n",
        "    'icd_code':    le_icd.transform(y_clf['icd_code']),\n",
        "    'drug':        le_drug.transform(y_clf['drug']),\n",
        "    'dose_unit_rx':le_unit.transform(y_clf['dose_unit_rx']),\n",
        "})\n",
        "\n",
        "# 4) Scale numeric features & regression targets\n",
        "num_feats = X.select_dtypes(include=['int64','float64']).columns\n",
        "scaler_X = StandardScaler().fit(X[num_feats])\n",
        "X[num_feats] = scaler_X.transform(X[num_feats])\n",
        "\n",
        "scaler_y = StandardScaler().fit(y_reg)\n",
        "y_reg_scaled = pd.DataFrame(scaler_y.transform(y_reg), columns=TARGET_REG)\n",
        "\n",
        "# 5) Build a PyTorch Dataset\n",
        "class HospDataset(Dataset):\n",
        "    def __init__(self, X, y_clf, y_reg):\n",
        "        self.X = torch.from_numpy(X.values).float()\n",
        "        self.y_clf = torch.from_numpy(y_clf.values).long()\n",
        "        self.y_reg = torch.from_numpy(y_reg.values).float()\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, i):\n",
        "        return self.X[i], self.y_clf[i], self.y_reg[i]\n",
        "\n",
        "# train/test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_tr, X_te, ycl_tr, ycl_te, yr_tr, yr_te = train_test_split(\n",
        "    X, y_clf_enc, y_reg_scaled, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "train_ds = HospDataset(X_tr, ycl_tr, yr_tr)\n",
        "test_ds  = HospDataset(X_te, ycl_te, yr_te)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=64)\n",
        "\n",
        "# 6) Define the multi-task model\n",
        "class MultiTaskNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, out_icd, out_drug, out_unit):\n",
        "        super().__init__()\n",
        "        self.shared = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        # classification heads\n",
        "        self.head_icd  = nn.Linear(hidden_dim//2, out_icd)\n",
        "        self.head_drug = nn.Linear(hidden_dim//2, out_drug)\n",
        "        self.head_unit = nn.Linear(hidden_dim//2, out_unit)\n",
        "        # regression head\n",
        "        self.head_reg  = nn.Linear(hidden_dim//2, 3)  # dose_val, start, stop\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.shared(x)\n",
        "        icd_logits  = self.head_icd(h)\n",
        "        drug_logits = self.head_drug(h)\n",
        "        unit_logits = self.head_unit(h)\n",
        "        reg_out     = self.head_reg(h)\n",
        "        return icd_logits, drug_logits, unit_logits, reg_out\n",
        "\n",
        "# instantiate\n",
        "model = MultiTaskNet(\n",
        "    input_dim   = X.shape[1],\n",
        "    hidden_dim  = 256,\n",
        "    out_icd     = len(le_icd.classes_),\n",
        "    out_drug    = len(le_drug.classes_),\n",
        "    out_unit    = len(le_unit.classes_)\n",
        ")\n",
        "\n",
        "# 7) Losses & optimizer\n",
        "criterion_clf = nn.CrossEntropyLoss()\n",
        "criterion_reg = nn.MSELoss()\n",
        "optimizer     = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# 8) Training loop\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for Xb, ycl_b, yr_b in train_loader:\n",
        "        Xb, ycl_b, yr_b = Xb.to(device), ycl_b.to(device), yr_b.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        icd_logits, drug_logits, unit_logits, reg_out = model(Xb)\n",
        "\n",
        "        # compute losses\n",
        "        loss_icd  = criterion_clf(icd_logits,  ycl_b[:,0])\n",
        "        loss_drug = criterion_clf(drug_logits, ycl_b[:,1])\n",
        "        loss_unit = criterion_clf(unit_logits, ycl_b[:,2])\n",
        "        loss_reg  = criterion_reg(reg_out, yr_b)\n",
        "\n",
        "        loss = loss_icd + loss_drug + loss_unit + loss_reg\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} — loss: {avg_loss:.4f}\")\n",
        "\n",
        "# 9) Quick evaluation on test set\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct_icd = correct_drug = correct_unit = total = 0\n",
        "    mse_reg = 0\n",
        "    for Xb, ycl_b, yr_b in test_loader:\n",
        "        Xb, ycl_b, yr_b = Xb.to(device), ycl_b.to(device), yr_b.to(device)\n",
        "        icd_logits, drug_logits, unit_logits, reg_out = model(Xb)\n",
        "\n",
        "        # classification accuracy\n",
        "        pred_icd  = icd_logits.argmax(dim=1)\n",
        "        pred_drug = drug_logits.argmax(dim=1)\n",
        "        pred_unit = unit_logits.argmax(dim=1)\n",
        "\n",
        "        correct_icd  += (pred_icd  == ycl_b[:,0]).sum().item()\n",
        "        correct_drug += (pred_drug == ycl_b[:,1]).sum().item()\n",
        "        correct_unit += (pred_unit == ycl_b[:,2]).sum().item()\n",
        "        total       += Xb.size(0)\n",
        "\n",
        "        # regression MSE\n",
        "        mse_reg += criterion_reg(reg_out, yr_b).item() * Xb.size(0)\n",
        "\n",
        "    print(\"Test ICD acc:\",  correct_icd/total)\n",
        "    print(\"Test Drug acc:\", correct_drug/total)\n",
        "    print(\"Test Unit acc:\", correct_unit/total)\n",
        "    print(\"Test Reg MSE:\", mse_reg/total)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V6E1",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}